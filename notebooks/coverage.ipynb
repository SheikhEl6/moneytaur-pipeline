{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoneyTaur Pipeline Coverage Analysis\n",
    "\n",
    "This notebook provides coverage analysis and testing utilities for the MoneyTaur data pipeline.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Ingestion Coverage**: Analysis of data source coverage and completeness\n",
    "- **ETL Coverage**: Validation of data transformation and normalization processes\n",
    "- **Enrichment Coverage**: Testing of OpenAI embedding pipeline\n",
    "- **API Coverage**: Testing of FastAPI endpoints and functionality\n",
    "\n",
    "## Setup\n",
    "\n",
    "Make sure to set your OPENAI_API_KEY environment variable before running enrichment tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for module imports\n",
    "sys.path.append(str(Path('../').resolve()))\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion Coverage\n",
    "\n",
    "Test the weekly index ingestion functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ingestion module\n",
    "try:\n",
    "    from ingest.weekly_index_ingest import WeeklyIndexIngestor\n",
    "    \n",
    "    ingestor = WeeklyIndexIngestor()\n",
    "    weekly_links = ingestor.process_year(2024)\n",
    "    \n",
    "    print(f'Ingestion test successful: Found {len(weekly_links)} weekly links')\n",
    "    print('Sample weekly links:')\n",
    "    for link in weekly_links[:3]:\n",
    "        print(f'  {link}')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'Ingestion test failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Coverage\n",
    "\n",
    "Test the SQLite normalization and data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ETL module\n",
    "try:\n",
    "    from etl.normalize import SQLiteNormalizer\n",
    "    \n",
    "    normalizer = SQLiteNormalizer('test_pipeline.db')\n",
    "    schema_created = normalizer.create_schema()\n",
    "    \n",
    "    if schema_created:\n",
    "        print('ETL test successful: Database schema created')\n",
    "        \n",
    "        # Create sample data\n",
    "        sample_data = pd.DataFrame({\n",
    "            'symbol': ['AAPL', 'GOOGL', 'MSFT'],\n",
    "            'date': ['2024-08-01', '2024-08-01', '2024-08-01'],\n",
    "            'close_price': [220.50, 2800.25, 415.75]\n",
    "        })\n",
    "        \n",
    "        load_success = normalizer.load_financial_data(sample_data)\n",
    "        if load_success:\n",
    "            print('Sample data loaded successfully')\n",
    "        else:\n",
    "            print('Failed to load sample data')\n",
    "    else:\n",
    "        print('ETL test failed: Could not create database schema')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'ETL test failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Coverage\n",
    "\n",
    "Test the OpenAI embedding pipeline (requires OPENAI_API_KEY):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test enrichment module\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    try:\n",
    "        from enrich.embed import DataEmbedder\n",
    "        \n",
    "        embedder = DataEmbedder()\n",
    "        \n",
    "        # Test with sample data\n",
    "        sample_df = pd.DataFrame({\n",
    "            'symbol': ['AAPL', 'GOOGL'],\n",
    "            'description': ['Apple Inc technology company', 'Google parent company Alphabet'],\n",
    "            'price': [220.50, 2800.25]\n",
    "        })\n",
    "        \n",
    "        enriched_df = embedder.create_embeddings_for_dataframe(sample_df, ['description'])\n",
    "        \n",
    "        if 'embedding' in enriched_df.columns:\n",
    "            print('Enrichment test successful: Embeddings created')\n",
    "            print(f'Embedding dimension: {len(enriched_df.iloc[0][\"embedding\"])}')\n",
    "        else:\n",
    "            print('Enrichment test failed: No embeddings created')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'Enrichment test failed: {e}')\n",
    "else:\n",
    "    print('OPENAI_API_KEY not set - skipping enrichment test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Coverage\n",
    "\n",
    "Basic API endpoint validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API module\n",
    "try:\n",
    "    # Import the app to verify it can be loaded\n",
    "    from api.app import app\n",
    "    \n",
    "    if app:\n",
    "        print('API test successful: FastAPI app loaded')\n",
    "        print(f'API title: {app.title}')\n",
    "        print(f'API version: {app.version}')\n",
    "        \n",
    "        # Check if routes are defined\n",
    "        route_paths = [route.path for route in app.routes if hasattr(route, 'path')]\n",
    "        search_endpoint = any('/search' in path for path in route_paths)\n",
    "        \n",
    "        if search_endpoint:\n",
    "            print('Search endpoint found')\n",
    "        else:\n",
    "            print('Search endpoint not found')\n",
    "            \n",
    "        print(f'Total routes: {len(route_paths)}')\n",
    "    else:\n",
    "        print('API test failed: FastAPI app is None')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'API test failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage Summary\n",
    "\n",
    "Run all tests and provide a summary report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_coverage_analysis():\n",
    "    \"\"\"Run comprehensive coverage analysis of the MoneyTaur pipeline.\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'ingestion': False,\n",
    "        'etl': False,\n",
    "        'enrichment': False,\n",
    "        'api': False\n",
    "    }\n",
    "    \n",
    "    # Test each module\n",
    "    try:\n",
    "        from ingest.weekly_index_ingest import WeeklyIndexIngestor\n",
    "        results['ingestion'] = True\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        from etl.normalize import SQLiteNormalizer\n",
    "        results['etl'] = True\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        from enrich.embed import DataEmbedder\n",
    "        results['enrichment'] = True\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        from api.app import app\n",
    "        results['api'] = True\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Print summary\n",
    "    print('\\n=== MONEYTAUR PIPELINE COVERAGE SUMMARY ===')\n",
    "    total_modules = len(results)\n",
    "    passed_modules = sum(results.values())\n",
    "    coverage_pct = (passed_modules / total_modules) * 100\n",
    "    \n",
    "    for module, status in results.items():\n",
    "        status_str = 'PASS' if status else 'FAIL'\n",
    "        print(f'{module.upper():>12}: {status_str}')\n",
    "    \n",
    "    print(f'\\nCoverage: {passed_modules}/{total_modules} ({coverage_pct:.1f}%)')\n",
    "    \n",
    "    if coverage_pct == 100:\n",
    "        print('✅ All pipeline modules are available!')\n",
    "    else:\n",
    "        print('⚠️  Some pipeline modules have issues')\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Run the coverage analysis\n",
    "coverage_results = run_coverage_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
